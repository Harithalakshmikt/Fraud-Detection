{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f955ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88921834",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731660a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 2018-04-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-04-30.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-30.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-05-31.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-06-30.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-30.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-07-31.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-30.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-08-31.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-01.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-02.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-03.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-04.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-05.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-06.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-07.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-08.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-09.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-10.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-11.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-12.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-13.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-14.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-15.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-16.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-17.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-18.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-19.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-20.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-21.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-22.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-23.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-24.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-25.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-26.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-27.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-28.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-29.pkl: <class 'pandas.core.frame.DataFrame'>\n",
      "Contents of 2018-09-30.pkl: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"D:\\Downloads\\Projects-20240722T093004Z-001\\Projects\\fraud_detection\\fraud_detection\\dataset\\data\"\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pkl\"):  # Ensure it's a .pkl file\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            print(f\"Contents of {file}: {type(data)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbc581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9488 entries, 0 to 9487\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   TRANSACTION_ID     9488 non-null   int64         \n",
      " 1   TX_DATETIME        9488 non-null   datetime64[ns]\n",
      " 2   CUSTOMER_ID        9488 non-null   object        \n",
      " 3   TERMINAL_ID        9488 non-null   object        \n",
      " 4   TX_AMOUNT          9488 non-null   float64       \n",
      " 5   TX_TIME_SECONDS    9488 non-null   object        \n",
      " 6   TX_TIME_DAYS       9488 non-null   object        \n",
      " 7   TX_FRAUD           9488 non-null   int64         \n",
      " 8   TX_FRAUD_SCENARIO  9488 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(4)\n",
      "memory usage: 741.2+ KB\n",
      "None\n",
      "   TRANSACTION_ID         TX_DATETIME CUSTOMER_ID TERMINAL_ID  TX_AMOUNT  \\\n",
      "0               0 2018-04-01 00:00:31         596        3156      57.16   \n",
      "1               1 2018-04-01 00:02:10        4961        3412      81.51   \n",
      "2               2 2018-04-01 00:07:56           2        1365     146.00   \n",
      "3               3 2018-04-01 00:09:29        4128        8737      64.49   \n",
      "4               4 2018-04-01 00:10:34         927        9906      50.99   \n",
      "\n",
      "  TX_TIME_SECONDS TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \n",
      "0              31            0         0                  0  \n",
      "1             130            0         0                  0  \n",
      "2             476            0         0                  0  \n",
      "3             569            0         0                  0  \n",
      "4             634            0         0                  0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_path = \"D:\\\\Downloads\\\\Projects-20240722T093004Z-001\\\\Projects\\\\fraud_detection\\\\fraud_detection\\\\dataset\\\\data\"\n",
    "\n",
    "# Pick one file to inspect\n",
    "sample_file = os.listdir(folder_path)[0]  # First file in the directory\n",
    "sample_path = os.path.join(folder_path, sample_file)\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_pickle(sample_path)\n",
    "\n",
    "# Display basic info\n",
    "print(df.info())\n",
    "print(df.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_FRAUD-0-Legimate\n",
    "#1-fraud  \n",
    "#Target or class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f531117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSACTION_ID       0\n",
      "TX_DATETIME          0\n",
      "CUSTOMER_ID          0\n",
      "TERMINAL_ID          0\n",
      "TX_AMOUNT            0\n",
      "TX_TIME_SECONDS      0\n",
      "TX_TIME_DAYS         0\n",
      "TX_FRAUD             0\n",
      "TX_FRAUD_SCENARIO    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9703b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a89477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TRANSACTION_ID    TX_AMOUNT     TX_FRAUD  TX_FRAUD_SCENARIO\n",
      "count     9488.000000  9488.000000  9488.000000        9488.000000\n",
      "mean      4743.500000    53.249981     0.000316           0.000316\n",
      "std       2739.094011    39.504071     0.017780           0.017780\n",
      "min          0.000000     0.130000     0.000000           0.000000\n",
      "25%       2371.750000    21.197500     0.000000           0.000000\n",
      "50%       4743.500000    45.590000     0.000000           0.000000\n",
      "75%       7115.250000    76.932500     0.000000           0.000000\n",
      "max       9487.000000   226.400000     1.000000           1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ea41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kthar\\AppData\\Local\\Temp\\ipykernel_20548\\1387791998.py:24: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  X = pd.get_dummies(X, columns=['CUSTOMER_ID', 'TERMINAL_ID'], drop_first=True)\n",
      "C:\\Users\\kthar\\AppData\\Local\\Temp\\ipykernel_20548\\1387791998.py:24: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  X = pd.get_dummies(X, columns=['CUSTOMER_ID', 'TERMINAL_ID'], drop_first=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kthar\\anaconda3\\envs\\new_gpu\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:15:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Target variable\n",
    "y = df['TX_FRAUD']\n",
    "\n",
    "# Drop irrelevant columns\n",
    "X = df.drop(['TRANSACTION_ID', 'TX_DATETIME', 'TX_FRAUD'], axis=1)\n",
    "\n",
    "# Add datetime-derived features\n",
    "X['TX_HOUR'] = df['TX_DATETIME'].dt.hour\n",
    "X['TX_DAYOFWEEK'] = df['TX_DATETIME'].dt.dayofweek\n",
    "\n",
    "# Ensure numeric for time features\n",
    "X['TX_TIME_SECONDS'] = X['TX_TIME_SECONDS'].astype(int)\n",
    "X['TX_TIME_DAYS'] = X['TX_TIME_DAYS'].astype(int)\n",
    "\n",
    "# Drop or ignore TX_DAY if object type and not needed\n",
    "if 'TX_DAY' in X.columns:\n",
    "    del X['TX_DAY']  # or encode it properly later\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X = pd.get_dummies(X, columns=['CUSTOMER_ID', 'TERMINAL_ID'], drop_first=True)\n",
    "\n",
    "# Confirm no object dtypes remain\n",
    "print(X.dtypes[X.dtypes == 'object'])  # should print nothing\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3f741",
   "metadata": {},
   "source": [
    "\n",
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b480535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "ROC AUC: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2846\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00      2847\n",
      "   macro avg       1.00      1.00      1.00      2847\n",
      "weighted avg       1.00      1.00      1.00      2847\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2846    0]\n",
      " [   0    1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Scores\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e4bcea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2083cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52278c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
